{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras import activations\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "# import cv2\n",
    "\n",
    "print(\"Num GPUs Available: \", tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "def plot_history_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogvscat = \"./train/\"\n",
    "IMG_SIZE=128\n",
    "batch_size = 30\n",
    "EAPOCHS = 20\n",
    "input = tf.keras.Input(shape = ((IMG_SIZE,IMG_SIZE,3)))\n",
    "train_dir=os.path.join('./', 'train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_SIZE, IMG_SIZE),)\n",
    "train_ds = train_ds.unbatch()\n",
    "train_xs = []\n",
    "train_ys = []\n",
    "for x,y in train_ds:\n",
    "    train_xs.append(x.astype('float32')/255.)\n",
    "    train_ys.append(y)\n",
    "train_xs = tf.convert_to_tensor(train_xs)\n",
    "train_ys = tf.convert_to_tensor(train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_SIZE, IMG_SIZE),)\n",
    "val_ds = val_ds.unbatch()\n",
    "test_xs = []\n",
    "test_ys = []\n",
    "for x,y in val_ds:\n",
    "    test_xs.append(x.astype('float32')/255.)\n",
    "    test_ys.append(y)\n",
    "test_xs = tf.convert_to_tensor(test_xs)\n",
    "test_ys = tf.convert_to_tensor(test_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same')(encoder_input)\n",
    "x = tf.keras.layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu',padding='same')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "x= tf.keras.layers.Flatten()(x)\n",
    "encoder_output = tf.keras.layers.Dense(512, activation='relu', name=\"ksks\")(x)\n",
    "\n",
    "\n",
    "decoder_input = tf.keras.layers.Dense(8192, activation='relu')(encoder_output)\n",
    "x = tf.keras.layers.Reshape((16,16,32))(decoder_input)\n",
    "x = tf.keras.layers.Conv2DTranspose(32, (3,3), strides=2, activation='relu' ,padding='same')(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(64, (3,3), strides=2, activation='relu' ,padding='same')(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(64, (3,3), strides=2, activation='relu' ,padding='same')(x)\n",
    "decoder_output = tf.keras.layers.Conv2D(3,(3,3),activation='relu' ,padding='same')(x)\n",
    "\n",
    "\n",
    "autoencoder = tf.keras.Model(inputs = encoder_input,outputs = decoder_output, name='ae')\n",
    "autoencoder.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.001,decay=1e-12)\n",
    "autoencoder.compile(loss = 'mse', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_autoencoder = autoencoder.fit(\n",
    "    train_xs,\n",
    "    train_xs,\n",
    "    batch_size = 30,\n",
    "    validation_split=0.1,\n",
    "    epochs=EAPOCHS*5,\n",
    "  )\n",
    "autoencoder.save(f'autoencoder_for_cnn_128.h5')\n",
    "encoder_model = tf.keras.Model(encoder_input,encoder_output,name='encoder')\n",
    "encoder_model.save(f'encoder_for_cnn_128.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN with encoder from Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = tf.keras.models.load_model('encoder_for_cnn_128.h5')\n",
    "cnn_with_encoder_output = tf.keras.layers.Dense(1, activation='sigmoid')(encoder_output)\n",
    "cnn_with_encoder_model = tf.keras.Model(inputs = encoder_input,outputs = cnn_with_encoder_output, name='cnn_encoder')\n",
    "cnn_with_encoder_model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.0001,decay=1e-6)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = tf.keras.Model(encoder_input,encoder_output,name='encoder')\n",
    "autoencoder_for_cnn =  tf.keras.models.load_model('autoencoder_for_cnn_128.h5')\n",
    "for l1,l2 in zip(cnn_with_encoder_model.layers[:len(encoder_model.layers)],autoencoder_for_cnn.layers[0:len(encoder_model.layers)]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_with_encoder_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn_with_encoder = cnn_with_encoder_model.fit(\n",
    "    train_xs,\n",
    "    train_ys,\n",
    "    batch_size = 30,\n",
    "    validation_split=0.1,\n",
    "    epochs=EAPOCHS*5,\n",
    "    callbacks=[callback]\n",
    "  )\n",
    "cnn_with_encoder_model.save(f'cnn_with_encoder_model_128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_loss(history_autoencoder)\n",
    "plot_history_loss(history_cnn_with_encoder)\n",
    "plot_history_accuracy(history_cnn_with_encoder)\n",
    "print(cnn_with_encoder_model.evaluate(test_xs,test_ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input = input\n",
    "x = tf.keras.layers.Conv2D(32, (4,4), activation='relu',padding='same')(cnn_input)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu',padding='same')(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same')(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "cnn_Amos = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(cnn_Amos)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "cnn_output =   tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "cnn_model = tf.keras.Model(inputs = cnn_input,outputs = cnn_output, name='cnn')\n",
    "cnn_model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.0001,decay=1e-9)\n",
    "# opt = tf.keras.optimizers.RMSprop(learning_rate= 0.001,decay=1e-6)\n",
    "cnn_model.compile(loss = tf.losses.BinaryCrossentropy(), optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn = cnn_model.fit(\n",
    "    train_xs,\n",
    "    train_ys,\n",
    "    batch_size = 30,\n",
    "    validation_split=0.1,\n",
    "    epochs=int(EAPOCHS*12),\n",
    "    callbacks=[callback]\n",
    "  )\n",
    "# cnn_model.save(f'cnn_model_128_2048.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_loss(history_cnn)\n",
    "plot_history_accuracy(history_cnn)\n",
    "print(cnn_model.evaluate(test_xs,test_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_with_encoder_model\n",
    "import matplotlib.pyplot as plt\n",
    "img = tf.keras.utils.load_img(dogvscat+'dog/dog.2.jpg', target_size=(IMG_SIZE,IMG_SIZE))\n",
    "#img=tf.zeros([100,100,3])\n",
    "layer=tf.keras.Model(inputs=model.input,outputs=model.layers[2].output)\n",
    "# img=tf.random.uniform((IMG_SIZE,IMG_SIZE,3))\n",
    "img=tf.keras.utils.img_to_array(img)\n",
    "img=tf.expand_dims(img, axis=0)\n",
    "feature_map=layer.predict(img)\n",
    "square = 10\n",
    "ix = 1\n",
    "fig=plt.figure(figsize=(30,30))\n",
    "k=2\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        # specify subplot and turn of axis\n",
    "        if sum(sum(feature_map[0, :, :, ix-1]))>0.7:\n",
    "            ax = fig.add_subplot(square, square, k-1)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "            plt.imshow(feature_map[0, :, :, ix-1])\n",
    "            k+=1\n",
    "        ix += 1\n",
    "# show the figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
